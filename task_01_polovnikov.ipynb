{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2c5e0af-eb07-496a-a0bc-63b499404d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from copy import deepcopy\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "48b00595-8fee-48a2-a3c5-f9c69c61b075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !wget https://gitlab.com/evgeny.zavalnyuk/sirius_ml_labs/-/raw/main/ps1/sales.txt\n",
    "sales_path='sales.txt'\n",
    "sales=pd.read_csv(sales_path, names=['sqft', 'nbedrooms', 'price'])\n",
    "sales['w0'] = np.ones(sales.shape[0], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580db349-96bc-48d5-8765-dec4cda6e57c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### OLS MATRIX SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3d96e56e-62d5-47e1-8b76-c07be60948d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([89597.9095428 ,   139.21067402, -8738.01911233])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct matrixes\n",
    "X = np.asarray(sales.loc[:, ['w0', 'sqft', 'nbedrooms']])\n",
    "Y = np.asarray(sales.price)\n",
    "\n",
    "# Y_pred = W * X => W = (Xt * X)^-1 * Xt * Y\n",
    "X_inv = np.linalg.inv(X.T @ X)\n",
    "W_opt = X_inv @ X.T @ Y\n",
    "W_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f63094-324c-4d2a-9769-754d98ad1b56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "8f4a7fcd-b702-4042-a8d6-976442943474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient(w, x, y):\n",
    "    y_pred = (w * x).sum(axis=1)\n",
    "    loss = np.square(y - y_pred).mean()\n",
    "    derivatives = np.hstack([\n",
    "        -2 * ( (y - y_pred) * x.w0 ).sum(),\n",
    "        -2 * ( (y - y_pred) * x.sqft ).sum(),\n",
    "        -2 * ( (y - y_pred) * x.nbedrooms ).sum()\n",
    "    ])\n",
    "    return loss, derivatives\n",
    "\n",
    "def get_loss(w, x, y):\n",
    "    y_pred = (w * x).sum(axis=1)\n",
    "    return np.square(y - y_pred).mean()\n",
    "                   \n",
    "def optimal_lr(w, x, y):\n",
    "    r = y - (w * x).sum(axis=1)\n",
    "    z = x * (gradient(w, x, y))[0]\n",
    "    return (r * z.sum(axis=1)).sum() / (z * z).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "403fec0c-149f-4beb-be66-c06f2ad8e016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4086560111.243777"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_loss(w, sales.loc[:, ['w0', 'sqft', 'nbedrooms']], sales.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "943ff7cd-22e0-4b1e-8a4b-78c7749e36ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086560111.243777, array([-63.06768956,  77.09485523,  19.17805223]))"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(w, sales.loc[:, ['w0', 'sqft', 'nbedrooms']], sales.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "16ff579f-cd23-4b31-a98d-e7b1a6fff942",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 100,  derives = [-1.81940067e+05 -1.48876971e+02  5.49750103e+04], loss = 64575.62888300343, w = [50766.12185906   139.62802117  2995.44532457]\n",
      "epoch = 200,  derives = [-8.50780639e+04 -7.93503454e+01  2.57071742e+04], loss = 64068.77587896599, w = [71367.39754417   139.3747379  -3229.46348128]\n",
      "epoch = 300,  derives = [-4.16953602e+04 -3.79389360e+01  1.25986649e+04], loss = 63960.479410383516, w = [80669.44068363   139.29381753 -6040.18114186]\n",
      "epoch = 400,  derives = [-1.69496675e+04 -1.16685674e+01  5.12151533e+03], loss = 63931.872898228205, w = [86005.849162     139.25894882 -7652.63736895]\n",
      "epoch = 500,  derives = [-6.57198338e+03 -4.96798079e+00  1.98579128e+03], loss = 63927.0598972748, w = [88199.37297906   139.22735006 -8315.43544702]\n",
      "epoch = 600,  derives = [-2.12700377e+03 -1.66211638e+00  6.42695627e+02], loss = 63926.29745832384, w = [89144.69179293   139.21584961 -8601.07423553]\n",
      "epoch = 700,  derives = [-8.11107046e+02 -6.51554104e-01  2.45084141e+02], loss = 63926.22122244139, w = [89424.90561181   139.21257941 -8685.74401505]\n",
      "epoch = 800,  derives = [-2.30240656e+02 -1.71810221e-01  6.95695475e+01], loss = 63926.20929515217, w = [89548.93949777   139.21126778 -8723.22225848]\n",
      "epoch = 900,  derives = [-1.04514149e+02 -9.88395326e-02  3.15799764e+01], loss = 63926.208465256495, w = [89575.50573953   139.2108714  -8731.24954949]\n",
      "CPU times: user 25.3 s, sys: 0 ns, total: 25.3 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import scipy\n",
    "\n",
    "w = np.array([0, 0, 0])\n",
    "\n",
    "fd = lambda lr : get_loss(w - lr * grad, sales.loc[:, ['w0', 'sqft', 'nbedrooms']], sales.price)\n",
    "prev_loss = 0\n",
    "loss = 100\n",
    "counter = 0\n",
    "\n",
    "while abs(loss - prev_loss) > 0.1: # the stopping rule\n",
    "    prev_loss = loss\n",
    "    loss, grad = gradient(w, sales.loc[:, ['w0', 'sqft', 'nbedrooms']], sales.price)\n",
    "    alpha = scipy.optimize.minimize_scalar(fd) # suboptimal problem aka the fastest descent method\n",
    "    w = w - alpha.x * grad\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(f'epoch = {counter},  derives = {grad}, loss = {np.sqrt(loss)}, w = {w}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dceb124-b235-4f3d-9726-d6dbab1e0618",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### SKLEARN REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "726e653e-3744-4470-949f-5a78a8ecb6a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "888d9ede-a32d-48d9-a69b-52a4e1a87269",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([89597.9095428 ,   139.21067402, -8738.01911233]),\n",
       " 0.7329450180289142,\n",
       " 0.7329450180289142,\n",
       " 0.7329450180289142)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression(fit_intercept=False)\n",
    "lin_reg.fit(X, Y)\n",
    "lin_reg.coef_\n",
    "r_score = lin_reg.score(X, Y)\n",
    "\n",
    "r2 = 1 - ((Y - (X*lin_reg.coef_).sum(axis=1) )**2).sum() / ((Y - Y.mean())**2).sum()\n",
    "r2_score_lib = r2_score(Y, (X*lin_reg.coef_).sum(axis=1))\n",
    "lin_reg.coef_, r_score, r2, r2_score_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc01d5c-954d-41a6-82d6-86a575c1b672",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### GRADIENT DESCENT JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "e3390621-6901-473a-b818-69c8a19cedc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "899a0c3c-be68-414c-9880-5a7a16f393df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_loss(w, x, y):\n",
    "    y_pred = jnp.dot(x, w)\n",
    "    return jnp.sqrt(jnp.square(y - y_pred).mean())\n",
    "\n",
    "loss_grad = grad(fun=get_loss, argnums=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "3f53cecf-6ef1-4b30-9361-9a61b1e9ffe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_jnp = jnp.array([0, 0, 0], dtype=jnp.float32)\n",
    "X_jnp = jnp.asarray(sales.loc[:, ['w0', 'sqft', 'nbedrooms']], dtype=jnp.float32)\n",
    "Y_jnp = jnp.asarray(sales.price,  dtype=jnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe3eb9-ef29-4310-b860-6466b0c791a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import scipy\n",
    "\n",
    "prev_loss = 0\n",
    "loss = 100\n",
    "counter = 0\n",
    "\n",
    "W_jnp = jnp.array([-100, -100, -100], dtype=jnp.float32)\n",
    "X_jnp = jnp.asarray(sales.loc[:, ['w0', 'sqft', 'nbedrooms']])\n",
    "Y_jnp = jnp.asarray(sales.price)\n",
    "\n",
    "fd = lambda lr : get_loss(W_jnp - lr * grad_val,  X_jnp, Y_jnp)\n",
    "fd_grad = grad(fd)\n",
    "\n",
    "tol = 1e-7\n",
    "#alpha = 1e-3\n",
    "norm = 1\n",
    "alpha = 1.\n",
    "\n",
    "while norm > tol: # the stopping rule\n",
    "    norm = jnp.square(W_jnp-W_true).mean()\n",
    "    prev_loss = loss\n",
    "    loss = get_loss(W_jnp, X_jnp, Y_jnp)\n",
    "    grad_val = loss_grad(W_jnp, X_jnp, Y_jnp)\n",
    "    #alpha = scipy.optimize.minimize_scalar(fd) # suboptimal problem aka the fastest descent method\n",
    "    \n",
    "    if counter < 50:\n",
    "        alpha = scipy.optimize.minimize_scalar(fd).x # suboptimal problem aka the fastest descent method\n",
    "    else:\n",
    "        alpha = 10 * jnp.exp(-counter * 1e-5)\n",
    "    \n",
    "    # alpha = 1e-7\n",
    "    # for i in range(50):\n",
    "    #     a_grad = fd_grad(alpha)\n",
    "        #print(f'alpha = {alpha}, loss = {fd(alpha)}, grad = {a_grad}')\n",
    "        #print(len(str(int(a_grad))))\n",
    "        #a_grad = a_grad * 10 ** (-len(str(int(a_grad)))) * 1e-1\n",
    "        #alpha = alpha - a_grad\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(f'epoch = {counter},  derives = {grad_val}, alpha = {alpha}, loss = {loss}, w = {W_jnp}')\n",
    "        \n",
    "    W_jnp = W_jnp - alpha * grad_val * jnp.exp(0)\n",
    "        \n",
    "        \n",
    "print(f'estimated = {W_jnp}, true = {W_true}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "92c2fdc6-757d-4848-83cd-64e27db8c63c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_loss(w, x, y):\n",
    "    y_pred = (w * x).sum(axis=1)\n",
    "    return jnp.square(y - y_pred).mean()\n",
    "\n",
    "loss_grad = grad(fun=get_loss, argnums=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "6aa70043-44d1-4b71-bf80-24b9b374e790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1,  derives = [ 1.4601613 -3.9329948  3.3388686], alpha = 0.45790791511535645, loss = 7.0625901222229, w = [0. 0. 0.]\n",
      "epoch = 2,  derives = [ 0.7447395   0.19095409 -0.01559857], alpha = 0.9903147220611572, loss = 0.48153382539749146, w = [-0.66196656  1.7830297  -1.5136817 ]\n",
      "epoch = 3,  derives = [ 0.03411987 -0.58463913 -0.4215534 ], alpha = 0.9536437392234802, loss = 0.23318345844745636, w = [-1.3848891  1.5976696 -1.49854  ]\n",
      "epoch = 4,  derives = [0.507192   0.61516744 0.16041796], alpha = 0.9192235469818115, loss = 0.1819574534893036, w = [-1.4164656  2.1387293 -1.1084095]\n",
      "epoch = 5,  derives = [-0.22898938 -0.8513918  -0.29063815], alpha = 0.8879203796386719, loss = 0.19304361939430237, w = [-1.8644077  1.5954256 -1.2500875]\n",
      "epoch = 6,  derives = [0.43204594 0.89476156 0.15340976], alpha = 0.867331862449646, loss = 0.21143034100532532, w = [-1.6709995  2.3145247 -1.0046098]\n",
      "epoch = 7,  derives = [-0.29770172 -0.9718285  -0.17948818], alpha = 0.8597367405891418, loss = 0.217521533370018, w = [-2.0239043  1.5836633 -1.1299183]\n",
      "epoch = 8,  derives = [0.36612093 0.9521559  0.1057639 ], alpha = 0.8607882261276245, loss = 0.21271884441375732, w = [-1.7852627  2.362694  -0.9860382]\n",
      "epoch = 9,  derives = [-0.29493788 -0.9525088  -0.11117682], alpha = 0.8658924102783203, loss = 0.20272541046142578, w = [-2.0761852  1.6061037 -1.070079 ]\n",
      "epoch = 10,  derives = [0.31688687 0.9181521  0.07643631], alpha = 0.8726422190666199, loss = 0.19080990552902222, w = [-1.8427814  2.359887  -0.9820974]\n",
      "epoch = 11,  derives = [-0.27864337 -0.89671797 -0.07779825], alpha = 0.8800413608551025, loss = 0.17829690873622894, w = [-2.0929952  1.6349146 -1.0424515]\n",
      "epoch = 12,  derives = [0.2823361  0.8613212  0.06145002], alpha = 0.8876912593841553, loss = 0.1656893938779831, w = [-1.8733208  2.3418612 -0.9811176]\n",
      "epoch = 13,  derives = [-0.25925255 -0.83204365 -0.06113869], alpha = 0.895422637462616, loss = 0.1531892716884613, w = [-2.0956073  1.6637332 -1.0294979]\n",
      "epoch = 14,  derives = [0.25482458 0.79643714 0.05281827], alpha = 0.9031542539596558, loss = 0.1408909410238266, w = [-1.8917657   2.3179412  -0.98142654]\n",
      "epoch = 15,  derives = [-0.23829766 -0.76329577 -0.05158119], alpha = 0.9108368158340454, loss = 0.12884972989559174, w = [-2.091845   1.6926069 -1.0228976]\n",
      "epoch = 16,  derives = [0.22999063 0.7269704  0.04668271], alpha = 0.9184345602989197, loss = 0.11710621416568756, w = [-1.9050281  2.2910037 -0.9824598]\n",
      "epoch = 17,  derives = [-0.21611966 -0.6913719  -0.0449015 ], alpha = 0.9259141087532043, loss = 0.1056983470916748, w = [-2.0850277  1.7220489 -1.0189954]\n",
      "epoch = 18,  derives = [0.20580903 0.6539612  0.04142664], alpha = 0.9332413077354431, loss = 0.0946648120880127, w = [-1.9162034  2.2621217 -0.9839201]\n",
      "epoch = 19,  derives = [-0.19287086 -0.6165106  -0.03931442], alpha = 0.9403795003890991, loss = 0.08404731005430222, w = [-2.0766332  1.7523532 -1.0162126]\n",
      "epoch = 20,  derives = [0.1814275  0.57790875 0.03640579], alpha = 0.9472879767417908, loss = 0.07389117777347565, w = [-1.9266461  2.231786  -0.9856395]\n",
      "epoch = 21,  derives = [-0.16870499 -0.5390088  -0.03408743], alpha = 0.9539229869842529, loss = 0.06424564868211746, w = [-2.0673566  1.783575  -1.0138749]\n",
      "epoch = 22,  derives = [0.15659375 0.4993861  0.03139033], alpha = 0.9602369070053101, loss = 0.0551631860435009, w = [-1.936908   2.2003555 -0.9875173]\n",
      "epoch = 23,  derives = [-0.14387052 -0.4595345  -0.02895185], alpha = 0.9661800265312195, loss = 0.0466979555785656, w = [-2.0575805  1.8155246 -1.011707 ]\n",
      "epoch = 24,  derives = [0.13143942 0.41940147 0.02634131], alpha = 0.9717024564743042, loss = 0.03890366479754448, w = [-1.9471364  2.168292  -0.9894817]\n",
      "epoch = 25,  derives = [-0.11879792 -0.37938806 -0.02386141], alpha = 0.9767563343048096, loss = 0.03182997182011604, w = [-2.0476046  1.8477149 -1.0096161]\n",
      "epoch = 26,  derives = [0.10642701 0.33968335 0.02132879], alpha = 0.9812995195388794, loss = 0.025518616661429405, w = [-1.9572351  2.1363149 -0.9914648]\n",
      "epoch = 27,  derives = [-0.09417297 -0.30071852 -0.01889821], alpha = 0.9852996468544006, loss = 0.0199983399361372, w = [-2.0377612  1.8792994 -1.0076028]\n",
      "epoch = 28,  derives = [0.08234362 0.2628527  0.01650315], alpha = 0.9887385368347168, loss = 0.015279972925782204, w = [-1.9669282   2.105487   -0.99338835]\n",
      "epoch = 29,  derives = [-0.07095579 -0.22656736 -0.01423308], alpha = 0.9916151762008667, loss = 0.011351977474987507, w = [-2.0284615  1.9090645 -1.0057207]\n",
      "epoch = 30,  derives = [0.06023757 0.19230023 0.01207367], alpha = 0.993948757648468, loss = 0.008178092539310455, w = [-1.975813   2.0771751 -0.9951599]\n",
      "epoch = 31,  derives = [-0.05027042 -0.16051225 -0.01008155], alpha = 0.995778501033783, loss = 0.005697640124708414, w = [-2.020168   1.9355776 -1.0040501]\n",
      "epoch = 32,  derives = [0.04121596 0.13158163 0.00826121], alpha = 0.9971598982810974, loss = 0.0038289502263069153, w = [-1.983453    2.0528078  -0.99668705]\n",
      "epoch = 33,  derives = [-0.03314032 -0.10581426 -0.00664533], alpha = 0.9981620907783508, loss = 0.0024761008098721504, w = [-2.013297   1.9575313 -1.0026689]\n",
      "epoch = 34,  derives = [0.02611751 0.08338171 0.00523518], alpha = 0.9988580942153931, loss = 0.0015375501243397593, w = [-1.9895155  2.033464  -0.9979001]\n",
      "epoch = 35,  derives = [-0.02014659 -0.06432538 -0.00403968], alpha = 0.9993201494216919, loss = 0.0009150515543296933, w = [-2.008084   1.9741831 -1.0016221]\n",
      "epoch = 36,  derives = [0.01520467 0.04854209 0.00304781], alpha = 0.9996126294136047, loss = 0.0005211038514971733, w = [-1.9938966   2.0194817  -0.99877733]\n",
      "epoch = 37,  derives = [-0.01121539 -0.03580918 -0.00224874], alpha = 0.9997889995574951, loss = 0.0002835761697497219, w = [-2.0045004  1.9856281 -1.0009029]\n",
      "epoch = 38,  derives = [0.00808368 0.02580784 0.00162044], alpha = 0.9998903274536133, loss = 0.00014729586837347597, w = [-1.9967551   2.0103576  -0.99934995]\n",
      "epoch = 39,  derives = [-0.00568853 -0.01816249 -0.00114076], alpha = 0.9999457597732544, loss = 7.295127579709515e-05, w = [-2.0022826  1.9927106 -1.000458 ]\n",
      "epoch = 40,  derives = [0.00390783 0.01247575 0.00078344], alpha = 0.9999743700027466, loss = 3.442096203798428e-05, w = [-1.9984313  2.005007  -0.9996857]\n",
      "epoch = 41,  derives = [-0.00261864 -0.00836057 -0.00052528], alpha = 0.9999886751174927, loss = 1.5458148482139222e-05, w = [-2.0010507  1.9966445 -1.0002109]\n",
      "epoch = 42,  derives = [0.00171163 0.00546389 0.00034332], alpha = 0.999995231628418, loss = 6.6024090301652905e-06, w = [-1.9993129   2.002193   -0.99986225]\n",
      "epoch = 43,  derives = [-0.00109029 -0.00348104 -0.0002188 ], alpha = 0.9999982118606567, loss = 2.6798109047376784e-06, w = [-2.0004375  1.998603  -1.0000879]\n",
      "epoch = 44,  derives = [0.00067703 0.00216099 0.0001358 ], alpha = 0.9999994039535522, loss = 1.0327898962714244e-06, w = [-1.9997282  2.0008674 -0.9999455]\n",
      "epoch = 45,  derives = [-4.0938146e-04 -1.3066893e-03 -8.2319784e-05], alpha = 1.0, loss = 3.7762421811748936e-07, w = [-2.0001643  1.9994756 -1.000033 ]\n",
      "epoch = 46,  derives = [2.4102109e-04 7.6920149e-04 4.8419752e-05], alpha = 1.0, loss = 1.308589361315171e-07, w = [-1.9999032  2.0003088 -0.9999805]\n",
      "epoch = 47,  derives = [-1.3794271e-04 -4.4045539e-04 -2.7767512e-05], alpha = 1.0, loss = 4.2903526065174447e-08, w = [-2.0000553  1.9998232 -1.0000111]\n",
      "epoch = 48,  derives = [7.6904216e-05 2.4527396e-04 1.5445396e-05], alpha = 1.0, loss = 1.3306977741933679e-08, w = [-1.9999691   2.0000985  -0.99999374]\n",
      "epoch = 49,  derives = [-4.1592961e-05 -1.3283936e-04 -8.3778314e-06], alpha = 1.0, loss = 3.902353551410442e-09, w = [-2.0000167  1.9999467 -1.0000033]\n",
      "epoch = 50,  derives = [2.1908243e-05 7.0197704e-05 4.2924639e-06], alpha = 1.0, loss = 1.0888868695602127e-09, w = [-1.9999912  2.0000281 -0.9999982]\n",
      "epoch = 51,  derives = [-1.12535245e-05 -3.60627782e-05 -2.25768008e-06], alpha = 1.0, loss = 2.8745325564294433e-10, w = [-2.0000045  1.9999856 -1.0000008]\n",
      "estimated = [-1.9999977   2.0000072  -0.99999946], true = [-2.  2. -1.]\n",
      "CPU times: user 4.12 s, sys: 417 ms, total: 4.53 s\n",
      "Wall time: 3.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import scipy\n",
    "\n",
    "key = random.key(0)\n",
    "X_jnp = random.normal(key, shape=(10, 3), dtype=jnp.float32)\n",
    "W_true = random.choice(key, a=np.array([-2., -1., 1., 2.]), shape=(3,))\n",
    "Y_jnp = jnp.dot(X_jnp, W_true.T)\n",
    "\n",
    "W_jnp = jnp.array([0, 0, 0], dtype=jnp.float32)\n",
    "\n",
    "prev_loss = 0\n",
    "loss = 100\n",
    "counter = 0\n",
    "\n",
    "fd = lambda lr : get_loss(W_jnp - lr * grad_val,  X_jnp, Y_jnp)\n",
    "fd_grad = grad(fd)\n",
    "\n",
    "tol = 1e-10\n",
    "#alpha = 1e-3\n",
    "norm = 1\n",
    "\n",
    "while norm > tol: # the stopping rule\n",
    "    norm = jnp.square(W_jnp-W_true).mean()\n",
    "    prev_loss = loss\n",
    "    loss = get_loss(W_jnp, X_jnp, Y_jnp)\n",
    "    grad_val = loss_grad(W_jnp, X_jnp, Y_jnp)\n",
    "    #alpha = scipy.optimize.minimize_scalar(fd) # suboptimal problem aka the fastest descent method\n",
    "    \n",
    "    alpha = 1.\n",
    "    for i in range(10):\n",
    "        a_grad = fd_grad(alpha)\n",
    "        alpha = alpha - a_grad*1e-2\n",
    "        #print(f'alpha = {alpha}, loss = {fd(alpha)}, grad = {a_grad}')\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 1 == 0:\n",
    "        print(f'epoch = {counter},  derives = {grad_val}, alpha = {alpha}, loss = {loss}, w = {W_jnp}')\n",
    "        \n",
    "    W_jnp = W_jnp - alpha * grad_val * jnp.exp(-counter/100)\n",
    "        \n",
    "        \n",
    "print(f'estimated = {W_jnp}, true = {W_true}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59111bfe-e11f-4a5f-ac42-e12ffdd2333c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
